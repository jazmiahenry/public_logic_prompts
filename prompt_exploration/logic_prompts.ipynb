{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from jinja2 import Template\n",
    "import openai\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "dotenv_path = ('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path = dotenv_path, override = True)\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_VERSION\")\n",
    "openai.api_base = os.getenv(\"AZURE_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Logic Scenarios\n",
    "logic_scenarios = '../data/logic_input/logic_scenarios.xlsx'\n",
    "\n",
    "# Import Logic Prompt\n",
    "logic_prompt = '../data/logic_prompts/logic_prompts.jinja2'\n",
    "filled_prompt = '../data/logic_prompts/filled_logic_prompt.jinja2'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic Prompt Experiments\n",
    "\n",
    "This notebook explores three types of experiments with the purpose of mitigating bias while helping LLMs self reasonn using prompts."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbolic Logic and Counterfactual Data\n",
    "\n",
    "The first set of experiments explore if LLMs can be taught symbolic logic to better reason AND explores if identity of a sentence's subject causes the LLM to reason differently. This will be compared to how the LLM reasons without the symbolic logic prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counterfactual Examples\n",
    "\n",
    "GENDER = ['Gender-fluid', 'Nonbinary', 'Man', 'Woman', 'Transgender', 'Two Spirit', 'Intersex'] # By no means exhaustive list of gender identities and expressions\n",
    "RACE = ['Black', 'White', 'Hispanic', 'Middle Eastern', 'Asian', 'Native American', 'Pacific Islander'] # While Hispanic is an ethnicity, added to list for the sake of this exercise\n",
    "BLANK = ['Good', 'Bad']\n",
    "logic_df = pd.read_excel(logic_scenarios)\n",
    "logic_list = logic_df['scenarios'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_gender = random.choice(GENDER)\n",
    "random_race = random.choice(RACE)\n",
    "random_blank = random.choice(BLANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Prompt and Template\n",
    "with open(f'{logic_prompt}', 'r') as logic_file:\n",
    "    logic_template = Template(logic_file.read())\n",
    "\n",
    "render_logic = logic_template.render(\n",
    "    Gender = random_gender,\n",
    "    Race = random_race,\n",
    "    Blank = random_blank \n",
    ")\n",
    "# Output responses in a list\n",
    "res_list = []\n",
    "\n",
    "for i in range(len(logic_list)):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=engine, # Change to deployment name\n",
    "        messages = [{\"role\":\"system\",\"content\": render_logic},\n",
    "                    {'role': 'user', 'content': logic_list[i]}\n",
    "    ], \n",
    "        temperature=0,\n",
    "        max_tokens=350,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None)\n",
    "    res = response['choices'][0]['message']['content']\n",
    "    res_list.append(res)\n",
    "    \n",
    "print(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/logic_input/nonfilled_list.json', 'w') as notfilled_file:\n",
    "    json.dump(res_list, notfilled_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running With Tags Pre-Filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_list = []\n",
    "for logic in logic_list:\n",
    "    x = str(logic)\n",
    "    filled = x.format(RACE = random.choice(RACE), GENDER= random.choice(GENDER), BLANK = random.choice(BLANK))\n",
    "    filled_list.append(filled)\n",
    "filled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Prompt and Template\n",
    "with open(f'{filled_prompt}', 'r') as filled_file:\n",
    "    filled_template = Template(filled_file.read())\n",
    "\n",
    "render_filled = filled_template.render()\n",
    "\n",
    "# Collect all responses\n",
    "filled_log_list = []\n",
    "\n",
    "for i in range(len(filled_list)):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=engine, # Change to deployment name\n",
    "        messages = [{\"role\":\"system\",\"content\": render_filled},\n",
    "                    {'role': 'user', 'content': filled_list[i]}\n",
    "    ], \n",
    "        temperature=0,\n",
    "        max_tokens=350,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None)\n",
    "    res = response['choices'][0]['message']['content']\n",
    "    filled_log_list.append(res)\n",
    "    \n",
    "print(filled_log_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/logic_input/filled_list.json', 'w') as filled_file:\n",
    "    json.dump(filled_log_list, filled_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprompt_list = []\n",
    "for i in range(len(filled_list)):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=engine, # Change to deployment name\n",
    "        messages = [\n",
    "                    {'role': 'user', 'content': filled_list[i]}\n",
    "    ], \n",
    "        temperature=0,\n",
    "        max_tokens=350,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None)\n",
    "    res = response['choices'][0]['message']['content']\n",
    "    noprompt_list.append(res)\n",
    "print(noprompt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/logic_input/no_prompt.json', 'w') as noprompt_file:\n",
    "    json.dump(noprompt_list, noprompt_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
